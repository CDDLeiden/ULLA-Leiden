{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./init.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigments on uncertainty quantification and active learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [practical](../03_uncertainty_active_learning.ipynb), we introduced the concepts of uncertainty quantification\n",
    "and active learning. In the examples, we tried to predict calculated logP values which were synthetic data without noise.\n",
    "\n",
    "In this assignment, you will apply tools and concepts from the practical, but on more realistic data, _i.e._ data with noise.\n",
    "\n",
    "*Note: Only the conclusions, data and code presented in this notebook will be considered for grading. If there are other files that support your discussion, make sure they are clearly linked in this notebook.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Uncertainty estimation - effect of noise\n",
    "\n",
    "You can evaluate the effect of noise on the uncertainty estimation by adding synthetic `noise` to the clogP values\n",
    "\n",
    "> data['clogP'] = data['clogP'] + np.random.uniform(-`noise`, `noise`, size=len(data))\n",
    "\n",
    "By experimenting with output labels with a couple of different amplitudes of noise, try to answer how (and why) does the addition of noise affect\n",
    "1. the estimated _aleatoric_ uncertainty,\n",
    "2. the estimated _epistemic_ uncertainty,\n",
    "3. the _quality_ of the uncertainty estimation?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uncertainty estimation - effect of model complexity\n",
    "\n",
    "The source of the epistemic uncertainty is mainly the lack of data, but the model complexity can affect it too.\n",
    "\n",
    "By experimenting with a couple of different model complexity levels (by adding or removing layers*/hidden_nodes), try to answer how (and why) does the model complexity affect\n",
    "1. the estimated _aleatoric_ uncertainty,\n",
    "2. the estimated _epistemic_ uncertainty,\n",
    "3. the _quality_ of the uncertainty estimation?\n",
    "\n",
    "*You need to modify the layers in `self.linear_relu_stack`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Active learning - selection strategy\n",
    "\n",
    "Now, let's move real experimental data and create a model for adenosine a2a receptor (AA2AR,  [P29274](https://www.uniprot.org/uniprotkb/P29274/entry)) bioactivity predictions, and try to improve the model with active learning.\n",
    "\n",
    "In the practical, we selected at random the new training compounds at each active learning iteration. However, other selection strategies can be used: explorative (using uncerainty estimations or distance to the training set) or exploitative (using actvity predictions).\n",
    "\n",
    "Please build active learning schemes with the exploitative and expolaritive strategies (helper functions provided in [al_selection.py](al_selection.py) ) and comapre the results with the random selection scheme."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a2bproject_jan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb78dc314653a27287b19b8cfc9f3f4b2c88d6478009f490769a5c0d9a0841cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
